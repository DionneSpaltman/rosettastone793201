{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cadef5b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f89a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8fef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/Users/dionnespaltman/Desktop/Luiss/Machine Learning/Project/stopword_removal_dataframe.csv\") \n",
    "\n",
    "# Load multilingual model for embeddings \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "    return output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# Add embeddings\n",
    "df[\"embed1\"] = df[\"processed_language1\"].apply(lambda x: get_embedding(str(x)) if pd.notnull(x) else None)\n",
    "df[\"embed2\"] = df[\"processed_language2\"].apply(lambda x: get_embedding(str(x)) if pd.notnull(x) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ac7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/danielebiggi/Desktop/Data Science/Machine learning/rosettastone2/Daniele_notebooks/embedding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57454389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "df = pd.read_pickle(\"/Users/danielebiggi/Downloads/sentence_to_embedding.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary back to a DataFrame\n",
    "df = pd.DataFrame.from_dict(df, orient='index')\n",
    "df.to_csv(\"/Users/danielebiggi/Desktop/Data Science/Machine learning/rosettastone2/Daniele_notebooks/sentence_to_embedding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"ramsrigouthamg/t5_paraphraser\")\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"ramsrigouthamg/t5_paraphraser\")\n",
    "\n",
    "def paraphrase(text):\n",
    "    input_text = f\"paraphrase: {text} </s>\"\n",
    "    inputs = t5_tokenizer([input_text], return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = t5_model.generate(**inputs, max_length=60, num_return_sequences=1)\n",
    "    return t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Apply to one language \n",
    "df[\"sentence2_paraphrased\"] = df[\"sentence2\"].apply(lambda x: paraphrase(x) if pd.notnull(x) and \"en\" in x else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f67e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df[\"similarity_score\"] = df.apply(lambda row: cosine_similarity(row[\"embed1\"], row[\"embed2\"])[0][0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ee1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_size * 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7fb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mse = mean_squared_error(df[\"score\"], df[\"similarity_score\"])\n",
    "r2 = r2_score(df[\"score\"], df[\"similarity_score\"])\n",
    "\n",
    "print(f\"MSE: {mse:.3f}, RÂ²: {r2:.3f}\")\n",
    "plt.scatter(df[\"score\"], df[\"similarity_score\"])\n",
    "plt.xlabel(\"Human Score\")\n",
    "plt.ylabel(\"Model Score\")\n",
    "plt.title(\"Similarity Score Correlation\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosettastone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
