{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing \n",
    "Apply NLP techniques such as word embeddings, stemming, lemmatization, and stop-word removal.\n",
    "\n",
    "### Objective\n",
    "An alien civilization has discovered an ancient text file on the abandoned Earth, containing\n",
    "millions of sentence pairs. Their challenge is to decipher how closely related these sentence\n",
    "pairs are, effectively developing a semantic similarity detection model.\n",
    "\n",
    "### Dataset Features\n",
    "- Contains ~1 million lines with paired sentences.\n",
    "- Some sentence pairs share the same meaning, while others differ.\n",
    "- Requires feature engineering and text preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this file path \n",
    "file_path = \"/Users/dionnespaltman/Desktop/Luiss /Machine Learning/Project/rs2.csv\"\n",
    "\n",
    "# load the csv as a pandas dataframe \n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(949080, 5)\n"
     ]
    }
   ],
   "source": [
    "# print dimensions \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>score</th>\n",
       "      <th>lang1</th>\n",
       "      <th>lang2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ein Flugzeug hebt gerade ab.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ein Flugzeug hebt gerade ab.</td>\n",
       "      <td>Un avión está despegando.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>de</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ein Flugzeug hebt gerade ab.</td>\n",
       "      <td>Un avion est en train de décoller.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>de</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ein Flugzeug hebt gerade ab.</td>\n",
       "      <td>Un aereo sta decollando.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>de</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ein Flugzeug hebt gerade ab.</td>\n",
       "      <td>飛行機が離陸します。</td>\n",
       "      <td>5.0</td>\n",
       "      <td>de</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sentence1                           sentence2  score  \\\n",
       "0  Ein Flugzeug hebt gerade ab.         An air plane is taking off.    5.0   \n",
       "1  Ein Flugzeug hebt gerade ab.           Un avión está despegando.    5.0   \n",
       "2  Ein Flugzeug hebt gerade ab.  Un avion est en train de décoller.    5.0   \n",
       "3  Ein Flugzeug hebt gerade ab.            Un aereo sta decollando.    5.0   \n",
       "4  Ein Flugzeug hebt gerade ab.                          飛行機が離陸します。    5.0   \n",
       "\n",
       "  lang1 lang2  \n",
       "0    de    en  \n",
       "1    de    es  \n",
       "2    de    fr  \n",
       "3    de    it  \n",
       "4    de    ja  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the first 5 rows\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan: \n",
    "1. Lowercase all text\n",
    "2. Remove punctuation and special characters\n",
    "3. Remove stop words (for languages where this makes sense)\n",
    "4. Apply stemming or lemmatization\n",
    "5. Tokenization\n",
    "6. Word embeddings (later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import spacy\n",
    "from spacy.lang.xx import MultiLanguage\n",
    "import pandas as pd\n",
    "import string\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache loaded spaCy models\n",
    "loaded_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy_model(lang_code):\n",
    "    models = {\n",
    "        \"en\": \"en_core_web_sm\",\n",
    "        \"de\": \"de_core_news_sm\",\n",
    "        \"fr\": \"fr_core_news_sm\",\n",
    "        \"es\": \"es_core_news_sm\",\n",
    "        \"it\": \"it_core_news_sm\",\n",
    "        \"pt\": \"pt_core_news_sm\",\n",
    "        \"nl\": \"nl_core_news_sm\",\n",
    "        # Add more if needed\n",
    "    }\n",
    "    model_name = models.get(lang_code)\n",
    "    if model_name:\n",
    "        try:\n",
    "            return spacy.load(model_name)\n",
    "        except:\n",
    "            print(f\"⚠️ spaCy model {model_name} not found.\")\n",
    "            return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function \n",
    "# Lowercase, lemmatize, remove punctuation, remove stopwords\n",
    "def preprocess(text, lang_code):\n",
    "    nlp = load_spacy_model(lang_code)\n",
    "    if not nlp:\n",
    "        return text.lower()  # fallback\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc\n",
    "        if token.is_alpha and not token.is_stop\n",
    "    ]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have to run the following code in your terminal to make it work\n",
    "\n",
    "# python -m spacy download de_core_news_sm\n",
    "# python -m spacy download es_core_news_sm\n",
    "# python -m spacy download fr_core_news_sm\n",
    "# python -m spacy download it_core_news_sm\n",
    "# python -m spacy download ja_core_news_sm\n",
    "# python -m spacy download pt_core_news_sm\n",
    "# python -m spacy download nl_core_news_sm\n",
    "\n",
    "\n",
    "# also run \n",
    "# python -m spacy download de_core_news_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flugzeug heben\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(preprocess(\"Ein Flugzeug hebt gerade ab.\", \"de\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN | Original: The airplane is taking off.\n",
      "         Preprocessed: airplane take\n",
      "\n",
      "DE | Original: Ein Flugzeug hebt gerade ab.\n",
      "         Preprocessed: Flugzeug heben\n",
      "\n",
      "ES | Original: Un avión está despegando.\n",
      "         Preprocessed: avión despegar\n",
      "\n",
      "FR | Original: Un avion est en train de décoller.\n",
      "         Preprocessed: avion train décoller\n",
      "\n",
      "IT | Original: Un aereo sta decollando.\n",
      "         Preprocessed: aereo decollare\n",
      "\n",
      "PT | Original: Um avião está decolando.\n",
      "         Preprocessed: avião decolar\n",
      "\n",
      "NL | Original: Een vliegtuig is aan het opstijgen.\n",
      "         Preprocessed: vliegtuig opstijgen\n",
      "\n",
      "PL | Original: Samolot właśnie startuje.\n",
      "         Preprocessed: samolot właśnie startuje.\n",
      "\n",
      "RU | Original: Самолет взлетает.\n",
      "         Preprocessed: самолет взлетает.\n",
      "\n",
      "JA | Original: 飛行機が離陸します。\n",
      "         Preprocessed: 飛行機が離陸します。\n",
      "\n",
      "ZH | Original: 飞机正在起飞。\n",
      "         Preprocessed: 飞机正在起飞。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = {\n",
    "    \"en\": \"The airplane is taking off.\",\n",
    "    \"de\": \"Ein Flugzeug hebt gerade ab.\",\n",
    "    \"es\": \"Un avión está despegando.\",\n",
    "    \"fr\": \"Un avion est en train de décoller.\",\n",
    "    \"it\": \"Un aereo sta decollando.\",\n",
    "    \"pt\": \"Um avião está decolando.\",\n",
    "    \"nl\": \"Een vliegtuig is aan het opstijgen.\",\n",
    "    \"pl\": \"Samolot właśnie startuje.\",\n",
    "    \"ru\": \"Самолет взлетает.\",\n",
    "    \"ja\": \"飛行機が離陸します。\",\n",
    "    \"zh\": \"飞机正在起飞。\"\n",
    "}\n",
    "\n",
    "for lang, sentence in test_sentences.items():\n",
    "    print(f\"{lang.upper()} | Original: {sentence}\")\n",
    "    print(f\"         Preprocessed: {preprocess(sentence, lang)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy is not working for polish, russian, japanese and chinese. So we need to find a different solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the following in your terminal\n",
    "# pip install jieba\n",
    "# pip install spacy[ja]\n",
    "# python -m spacy download ja_core_news_sm\n",
    "# pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def preprocess_zh(text):\n",
    "    tokens = jieba.lcut(text)\n",
    "    # Optional: remove stopwords if you have a list\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp_ja = spacy.load(\"ja_core_news_sm\")\n",
    "\n",
    "def preprocess_ja(text):\n",
    "    doc = nlp_ja(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run the code below you need to downgrade your pytorch version\n",
    "# run in your terminal \n",
    "# pip install torch==2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:14:14.187948: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8821f1d22b8401984eaf5ae868d7200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:14:18 INFO: Downloaded file to /Users/dionnespaltman/stanza_resources/resources.json\n",
      "2025-03-27 12:14:18 INFO: Downloading default packages for language: ru (Russian) ...\n",
      "2025-03-27 12:14:20 INFO: File exists: /Users/dionnespaltman/stanza_resources/ru/default.zip\n",
      "2025-03-27 12:14:26 INFO: Finished downloading models and saved to /Users/dionnespaltman/stanza_resources\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be0d8b9becb43c2b90ee2e6e88c4fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:14:26 INFO: Downloaded file to /Users/dionnespaltman/stanza_resources/resources.json\n",
      "2025-03-27 12:14:26 INFO: Downloading default packages for language: pl (Polish) ...\n",
      "2025-03-27 12:14:27 INFO: File exists: /Users/dionnespaltman/stanza_resources/pl/default.zip\n",
      "2025-03-27 12:14:31 INFO: Finished downloading models and saved to /Users/dionnespaltman/stanza_resources\n",
      "2025-03-27 12:14:31 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7492c85f4e4ff786d02468d2637849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:14:31 INFO: Downloaded file to /Users/dionnespaltman/stanza_resources/resources.json\n",
      "2025-03-27 12:14:31 INFO: Loading these models for language: ru (Russian):\n",
      "==================================\n",
      "| Processor | Package            |\n",
      "----------------------------------\n",
      "| tokenize  | syntagrus          |\n",
      "| lemma     | syntagrus_nocharlm |\n",
      "==================================\n",
      "\n",
      "2025-03-27 12:14:31 INFO: Using device: cpu\n",
      "2025-03-27 12:14:31 INFO: Loading: tokenize\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "2025-03-27 12:14:31 INFO: Loading: lemma\n",
      "2025-03-27 12:14:36 INFO: Done loading processors!\n",
      "2025-03-27 12:14:36 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b7f878fa5d43c08b50f683f147ca77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:14:36 INFO: Downloaded file to /Users/dionnespaltman/stanza_resources/resources.json\n",
      "2025-03-27 12:14:36 WARNING: Language pl package default expects mwt, which has been added\n",
      "2025-03-27 12:14:36 INFO: Loading these models for language: pl (Polish):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | pdb          |\n",
      "| mwt       | pdb          |\n",
      "| lemma     | pdb_nocharlm |\n",
      "============================\n",
      "\n",
      "2025-03-27 12:14:36 INFO: Using device: cpu\n",
      "2025-03-27 12:14:36 INFO: Loading: tokenize\n",
      "2025-03-27 12:14:36 INFO: Loading: mwt\n",
      "2025-03-27 12:14:36 INFO: Loading: lemma\n",
      "2025-03-27 12:14:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "stanza.download(\"ru\")  # Russian\n",
    "stanza.download(\"pl\")  # Polish\n",
    "\n",
    "nlp_ru = stanza.Pipeline(\"ru\", processors=\"tokenize,lemma\", use_gpu=False)\n",
    "nlp_pl = stanza.Pipeline(\"pl\", processors=\"tokenize,lemma\", use_gpu=False)\n",
    "\n",
    "def preprocess_ru(text):\n",
    "    doc = nlp_ru(text)\n",
    "    tokens = [word.lemma for sent in doc.sentences for word in sent.words if word.lemma.isalpha()]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def preprocess_pl(text):\n",
    "    doc = nlp_pl(text)\n",
    "    tokens = [word.lemma for sent in doc.sentences for word in sent.words if word.lemma.isalpha()]\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, lang_code):\n",
    "    if lang_code == \"zh\":\n",
    "        return preprocess_zh(text)\n",
    "    elif lang_code == \"ja\":\n",
    "        return preprocess_ja(text)\n",
    "    elif lang_code == \"ru\":\n",
    "        return preprocess_ru(text)\n",
    "    elif lang_code == \"pl\":\n",
    "        return preprocess_pl(text)\n",
    "    else:\n",
    "        # fallback to spaCy\n",
    "        nlp = load_spacy_model(lang_code)\n",
    "        if not nlp:\n",
    "            return text.lower()\n",
    "        doc = nlp(text.lower())\n",
    "        tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "        return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN | Original: The airplane is taking off.\n",
      "         Preprocessed: airplane take\n",
      "\n",
      "DE | Original: Ein Flugzeug hebt gerade ab.\n",
      "         Preprocessed: Flugzeug heben\n",
      "\n",
      "ES | Original: Un avión está despegando.\n",
      "         Preprocessed: avión despegar\n",
      "\n",
      "FR | Original: Un avion est en train de décoller.\n",
      "         Preprocessed: avion train décoller\n",
      "\n",
      "IT | Original: Un aereo sta decollando.\n",
      "         Preprocessed: aereo decollare\n",
      "\n",
      "PT | Original: Um avião está decolando.\n",
      "         Preprocessed: avião decolar\n",
      "\n",
      "NL | Original: Een vliegtuig is aan het opstijgen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Preprocessed: vliegtuig opstijgen\n",
      "\n",
      "PL | Original: Samolot właśnie startuje.\n",
      "         Preprocessed: samolot właśnie startuje\n",
      "\n",
      "RU | Original: Самолет взлетает.\n",
      "         Preprocessed: самолет взлетать\n",
      "\n",
      "JA | Original: 飛行機が離陸します。\n",
      "         Preprocessed: 飛行 機 が 離陸 する ます\n",
      "\n",
      "ZH | Original: 飞机正在起飞。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache /var/folders/_4/nzq6mygj7j71_l3z_c9kc7wr0000gn/T/jieba.cache\n",
      "Loading model cost 0.973 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Preprocessed: 飞机 正在 起飞 。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = {\n",
    "    \"en\": \"The airplane is taking off.\",\n",
    "    \"de\": \"Ein Flugzeug hebt gerade ab.\",\n",
    "    \"es\": \"Un avión está despegando.\",\n",
    "    \"fr\": \"Un avion est en train de décoller.\",\n",
    "    \"it\": \"Un aereo sta decollando.\",\n",
    "    \"pt\": \"Um avião está decolando.\",\n",
    "    \"nl\": \"Een vliegtuig is aan het opstijgen.\",\n",
    "    \"pl\": \"Samolot właśnie startuje.\",\n",
    "    \"ru\": \"Самолет взлетает.\",\n",
    "    \"ja\": \"飛行機が離陸します。\",\n",
    "    \"zh\": \"飞机正在起飞。\"\n",
    "}\n",
    "\n",
    "for lang, sentence in test_sentences.items():\n",
    "    print(f\"{lang.upper()} | Original: {sentence}\")\n",
    "    print(f\"         Preprocessed: {preprocess(sentence, lang)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the test is working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing sentence1:   0%|          | 400/949080 [05:24<469:05:27,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ spaCy model nl_core_news_sm not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing sentence1:   0%|          | 416/949080 [05:31<175:19:22,  1.50it/s]"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "tqdm.pandas(desc=\"Preprocessing sentence1\")\n",
    "df[\"sentence1_clean\"] = df.progress_apply(\n",
    "    lambda row: preprocess(row[\"sentence1\"], row[\"lang1\"]), axis=1\n",
    ")\n",
    "\n",
    "tqdm.pandas(desc=\"Preprocessing sentence2\")\n",
    "df[\"sentence2_clean\"] = df.progress_apply(\n",
    "    lambda row: preprocess(row[\"sentence2\"], row[\"lang2\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing complete! Cleaned data saved to 'rs2_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save or preview\n",
    "file_path_clean = \"/Users/dionnespaltman/Desktop/Luiss /Machine Learning/Project/rs2_cleaned.csv\"\n",
    "df.to_csv(file_path_clean, index=False)\n",
    "print(\"✅ Preprocessing complete! Cleaned data saved to 'rs2_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this file path \n",
    "file_path_clean = \"/Users/dionnespaltman/Desktop/Luiss /Machine Learning/Project/rs2_cleaned.csv\"\n",
    "\n",
    "# load the csv as a pandas dataframe \n",
    "df = pd.read_csv(file_path_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>score</th>\n",
       "      <th>lang1</th>\n",
       "      <th>lang2</th>\n",
       "      <th>sentence1_clean</th>\n",
       "      <th>sentence2_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ein Flugzeug hebt gerade ab.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>ein flugzeug hebt gerade ab.</td>\n",
       "      <td>air plane take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ein Flugzeug hebt gerade ab.</td>\n",
       "      <td>Un avión está despegando.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>de</td>\n",
       "      <td>es</td>\n",
       "      <td>ein flugzeug hebt gerade ab.</td>\n",
       "      <td>un avión está despegando.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ein Flugzeug hebt gerade ab.</td>\n",
       "      <td>Un avion est en train de décoller.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>de</td>\n",
       "      <td>fr</td>\n",
       "      <td>ein flugzeug hebt gerade ab.</td>\n",
       "      <td>un avion est en train de décoller.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ein Flugzeug hebt gerade ab.</td>\n",
       "      <td>Un aereo sta decollando.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>de</td>\n",
       "      <td>it</td>\n",
       "      <td>ein flugzeug hebt gerade ab.</td>\n",
       "      <td>un aereo sta decollando.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ein Flugzeug hebt gerade ab.</td>\n",
       "      <td>飛行機が離陸します。</td>\n",
       "      <td>5.0</td>\n",
       "      <td>de</td>\n",
       "      <td>ja</td>\n",
       "      <td>ein flugzeug hebt gerade ab.</td>\n",
       "      <td>飛行機が離陸します。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949075</th>\n",
       "      <td>韩国宣布MERS疫情结束</td>\n",
       "      <td>北朝鮮の代表団が韓国政府関係者と会談</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zh</td>\n",
       "      <td>ja</td>\n",
       "      <td>韩国宣布mers疫情结束</td>\n",
       "      <td>北朝鮮の代表団が韓国政府関係者と会談</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949076</th>\n",
       "      <td>韩国宣布MERS疫情结束</td>\n",
       "      <td>Delegatie Noord-Korea Ontmoetingen met Zuid-Ko...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zh</td>\n",
       "      <td>nl</td>\n",
       "      <td>韩国宣布mers疫情结束</td>\n",
       "      <td>delegatie noord-korea ontmoetingen met zuid-ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949077</th>\n",
       "      <td>韩国宣布MERS疫情结束</td>\n",
       "      <td>Delegacja Korei Północnej spotyka się z urzędn...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zh</td>\n",
       "      <td>pl</td>\n",
       "      <td>韩国宣布mers疫情结束</td>\n",
       "      <td>delegacja korei północnej spotyka się z urzędn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949078</th>\n",
       "      <td>韩国宣布MERS疫情结束</td>\n",
       "      <td>Delegação da Coreia do Norte reúne-se com func...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zh</td>\n",
       "      <td>pt</td>\n",
       "      <td>韩国宣布mers疫情结束</td>\n",
       "      <td>delegação da coreia do norte reúne-se com func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949079</th>\n",
       "      <td>韩国宣布MERS疫情结束</td>\n",
       "      <td>Делегация Северной Кореи встречается с южнокор...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zh</td>\n",
       "      <td>ru</td>\n",
       "      <td>韩国宣布mers疫情结束</td>\n",
       "      <td>делегация северной кореи встречается с южнокор...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949080 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           sentence1  \\\n",
       "0       Ein Flugzeug hebt gerade ab.   \n",
       "1       Ein Flugzeug hebt gerade ab.   \n",
       "2       Ein Flugzeug hebt gerade ab.   \n",
       "3       Ein Flugzeug hebt gerade ab.   \n",
       "4       Ein Flugzeug hebt gerade ab.   \n",
       "...                              ...   \n",
       "949075                  韩国宣布MERS疫情结束   \n",
       "949076                  韩国宣布MERS疫情结束   \n",
       "949077                  韩国宣布MERS疫情结束   \n",
       "949078                  韩国宣布MERS疫情结束   \n",
       "949079                  韩国宣布MERS疫情结束   \n",
       "\n",
       "                                                sentence2  score lang1 lang2  \\\n",
       "0                             An air plane is taking off.    5.0    de    en   \n",
       "1                               Un avión está despegando.    5.0    de    es   \n",
       "2                      Un avion est en train de décoller.    5.0    de    fr   \n",
       "3                                Un aereo sta decollando.    5.0    de    it   \n",
       "4                                              飛行機が離陸します。    5.0    de    ja   \n",
       "...                                                   ...    ...   ...   ...   \n",
       "949075                                 北朝鮮の代表団が韓国政府関係者と会談    0.0    zh    ja   \n",
       "949076  Delegatie Noord-Korea Ontmoetingen met Zuid-Ko...    0.0    zh    nl   \n",
       "949077  Delegacja Korei Północnej spotyka się z urzędn...    0.0    zh    pl   \n",
       "949078  Delegação da Coreia do Norte reúne-se com func...    0.0    zh    pt   \n",
       "949079  Делегация Северной Кореи встречается с южнокор...    0.0    zh    ru   \n",
       "\n",
       "                     sentence1_clean  \\\n",
       "0       ein flugzeug hebt gerade ab.   \n",
       "1       ein flugzeug hebt gerade ab.   \n",
       "2       ein flugzeug hebt gerade ab.   \n",
       "3       ein flugzeug hebt gerade ab.   \n",
       "4       ein flugzeug hebt gerade ab.   \n",
       "...                              ...   \n",
       "949075                  韩国宣布mers疫情结束   \n",
       "949076                  韩国宣布mers疫情结束   \n",
       "949077                  韩国宣布mers疫情结束   \n",
       "949078                  韩国宣布mers疫情结束   \n",
       "949079                  韩国宣布mers疫情结束   \n",
       "\n",
       "                                          sentence2_clean  \n",
       "0                                          air plane take  \n",
       "1                               un avión está despegando.  \n",
       "2                      un avion est en train de décoller.  \n",
       "3                                un aereo sta decollando.  \n",
       "4                                              飛行機が離陸します。  \n",
       "...                                                   ...  \n",
       "949075                                 北朝鮮の代表団が韓国政府関係者と会談  \n",
       "949076  delegatie noord-korea ontmoetingen met zuid-ko...  \n",
       "949077  delegacja korei północnej spotyka się z urzędn...  \n",
       "949078  delegação da coreia do norte reúne-se com func...  \n",
       "949079  делегация северной кореи встречается с южнокор...  \n",
       "\n",
       "[949080 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the first 5 rows\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
